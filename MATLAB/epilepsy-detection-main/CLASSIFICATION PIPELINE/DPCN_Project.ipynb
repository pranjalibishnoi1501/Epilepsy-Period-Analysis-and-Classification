{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fTwy1ViNm71A"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy.io\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.nn import Module\n",
        "from torch.nn import Conv2d\n",
        "from torch.nn import Linear\n",
        "from torch.nn import MaxPool2d\n",
        "from torch.nn import ReLU\n",
        "from torch.nn import LogSoftmax\n",
        "from torch.nn import Flatten\n",
        "from torch.nn import Flatten\n",
        "from torch.nn import Dropout\n",
        "from torch.nn import Sigmoid"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ig0sMeTMpbW1",
        "outputId": "19e6a0c7-6c9e-4afe-fd92-e672530d5260"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DataLoader(Dataset):\n",
        "    def __init__(self, data_mat, labels):\n",
        "        self.data_mat = data_mat\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data_mat.shape[2]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        mat = np.array(self.data_mat[:,:,idx], dtype=np.float32)\n",
        "        mat_pad = np.zeros((50,50), dtype=np.float32)\n",
        "        mat_pad[1:49, 1:49] = mat\n",
        "        adj_mat = np.expand_dims(mat_pad, 0)\n",
        "        label = [self.labels[idx], np.abs(1-self.labels[idx])]\n",
        "        return torch.from_numpy(adj_mat), torch.from_numpy(np.array(label, dtype=np.float32))"
      ],
      "metadata": {
        "id": "b5laDFCgqUeV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, numChannels=1, classes=2):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.layer1 = nn.Sequential(\n",
        "                            Conv2d(in_channels=numChannels, out_channels=32, kernel_size=(3,3)),\n",
        "                            ReLU(),\n",
        "                            MaxPool2d(kernel_size=(2, 2), stride=(2, 2)))\n",
        "        \n",
        "        self.layer2 = nn.Sequential(\n",
        "                            Conv2d(in_channels=32, out_channels=64,kernel_size=(3,3)),\n",
        "                            ReLU(),\n",
        "                            MaxPool2d(kernel_size=(2, 2), stride=(2, 2)))\n",
        "\n",
        "        self.flatten1 = Flatten(0,2)\n",
        "\n",
        "        self.fc1 = nn.Sequential(\n",
        "                            Linear(in_features=7744, out_features=128),\n",
        "                            ReLU())\n",
        "\n",
        "        self.dropout = Dropout(p=0.2)\n",
        "\n",
        "        self.fc2 = nn.Sequential(\n",
        "                            Linear(in_features=128, out_features=classes),\n",
        "                            Sigmoid())\n",
        "\n",
        "    def forward(self, x):\n",
        "      #print(\"x: \", x.shape)\n",
        "      x1 = self.layer1(x)\n",
        "      #print(\"x1:\", x1.shape)\n",
        "      x2 = self.layer2(x1)\n",
        "      #print(\"x2:\", x2.shape)\n",
        "      f1 = self.flatten1(x2)\n",
        "      #print(\"f1:\", f1.shape)\n",
        "      f2 = self.fc1(f1)\n",
        "      #print(\"f2:\", f2.shape)\n",
        "      f3 = self.dropout(f2)\n",
        "      #print(\"f3:\", f3.shape)\n",
        "      out = self.fc2(f3)\n",
        "      #print(\"out:\", out.shape)\n",
        "      return out"
      ],
      "metadata": {
        "id": "ynxfKuPsnMb3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = dataloader.__len__\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        #print(\"pred: \", pred, \"y: \", y)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        loss = loss.item()\n",
        "        #print(f\"loss: {loss:>7f}\")"
      ],
      "metadata": {
        "id": "mfSoxnwfqJNd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    tp = 0\n",
        "    fp = 0\n",
        "    tn = 0\n",
        "    fn = 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            out = pred\n",
        "            if(y[0] == 1):\n",
        "              if(out[0] >= out[1]):\n",
        "                tp += 1\n",
        "              elif(out[0] < out[1]):\n",
        "                #print(out)\n",
        "                fn += 1\n",
        "            elif(y[0] == 0):\n",
        "              if(out[0] >= out[1]):\n",
        "                fp += 1\n",
        "              elif(out[0] < out[1]):\n",
        "                tn += 1\n",
        "    #print(test_loss, num_batches)\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    #print(f\"Test Error: \\n Metrics: {[tp, fp, tn, fn]}, Avg loss: {test_loss:>8f} \\n\")\n",
        "    return [tp, fp, tn, fn], test_loss"
      ],
      "metadata": {
        "id": "aGK7Pd0jqL7X"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mat = scipy.io.loadmat('/content/theta_A_W_uni10_100ms.mat')[\"W\"]\n",
        "labels = []\n",
        "\n",
        "for i in range(250):\n",
        "  labels.append(0)\n",
        "\n",
        "for i in range(956):\n",
        "  labels.append(1)\n",
        "\n",
        "for i in range(250):\n",
        "  labels.append(0)\n",
        "\n",
        "labels = np.array(labels)\n",
        "\n",
        "a1 = np.arange(0,250)\n",
        "a2 = np.arange(250,250+956)\n",
        "a3 = np.arange(250+956,500+956)\n",
        "\n",
        "t1 = list(np.random.choice(a1, int(len(a1)*0.1), replace=False))\n",
        "tr1 = list(set(a1)-set(t1))\n",
        "t2 = list(np.random.choice(a2, int(len(a2)*0.1), replace=False))\n",
        "tr2 = list(set(a2)-set(t2))\n",
        "t3 = list(np.random.choice(a3, int(len(a3)*0.1), replace=False))\n",
        "tr3 = list(set(a3)-set(t3))\n",
        "\n",
        "t = t1 + t2 + t3\n",
        "tr = tr1 + tr2 + tr3\n",
        "test_data = mat[:,:,t]\n",
        "train_data = mat[:,:,tr]\n",
        "test_labels = labels[t]\n",
        "train_labels = labels[tr]\n",
        "\n",
        "print(len(t), len(tr))"
      ],
      "metadata": {
        "id": "S3WtJGpD3XE1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf33e6fe-069b-4756-ac59-77ea47f54fa0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "145 1311\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyaVy6S2_25m",
        "outputId": "429a1561-1b77-49fb-ae2a-b215bfe22056"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model(\n",
            "  (layer1): Sequential(\n",
            "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (flatten1): Flatten(start_dim=0, end_dim=2)\n",
            "  (fc1): Sequential(\n",
            "    (0): Linear(in_features=7744, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "  )\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            "  (fc2): Sequential(\n",
            "    (0): Linear(in_features=128, out_features=2, bias=True)\n",
            "    (1): Sigmoid()\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_data, train_labels)\n",
        "test_dataloader = DataLoader(test_data, test_labels)\n",
        "model = Model().to(device)\n",
        "loss_fn = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-6)\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [20], gamma=0.001)\n",
        "\n",
        "epochs = 50\n",
        "max_c = -1\n",
        "max_c_epoch = -1\n",
        "min_tl = 9999\n",
        "min_tl_epoch = 9999\n",
        "\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    #test(train_dataloader, model, loss_fn)\n",
        "    c, tl = test(test_dataloader, model, loss_fn)\n",
        "    acc = (c[0] + c[2])/np.sum(c)\n",
        "    pre = c[0]/(c[0]+c[1])\n",
        "    sen = c[0]/(c[0]+c[3])\n",
        "    spe = c[2]/(c[1]+c[2])\n",
        "    f_score = 2*(pre*sen)/(pre+sen)\n",
        "    print(\"acc: \", acc, \"pre: \", pre, \"rec: \", sen, \"spe: \", spe, \"f_score: \", f_score, \"c: \", c)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22_b33vSqPDe",
        "outputId": "8ebd81e9-1bc9-46c8-e528-728ffc89b712"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "acc:  0.6551724137931034 pre:  0.6551724137931034 rec:  1.0 spe:  0.0 f_score:  0.7916666666666666 c:  [95, 50, 0, 0]\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "acc:  0.6551724137931034 pre:  0.6551724137931034 rec:  1.0 spe:  0.0 f_score:  0.7916666666666666 c:  [95, 50, 0, 0]\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "acc:  0.6551724137931034 pre:  0.6551724137931034 rec:  1.0 spe:  0.0 f_score:  0.7916666666666666 c:  [95, 50, 0, 0]\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "acc:  0.6551724137931034 pre:  0.6551724137931034 rec:  1.0 spe:  0.0 f_score:  0.7916666666666666 c:  [95, 50, 0, 0]\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "acc:  0.6551724137931034 pre:  0.6551724137931034 rec:  1.0 spe:  0.0 f_score:  0.7916666666666666 c:  [95, 50, 0, 0]\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "acc:  0.6551724137931034 pre:  0.6551724137931034 rec:  1.0 spe:  0.0 f_score:  0.7916666666666666 c:  [95, 50, 0, 0]\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "acc:  0.6551724137931034 pre:  0.6551724137931034 rec:  1.0 spe:  0.0 f_score:  0.7916666666666666 c:  [95, 50, 0, 0]\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "acc:  0.6551724137931034 pre:  0.6551724137931034 rec:  1.0 spe:  0.0 f_score:  0.7916666666666666 c:  [95, 50, 0, 0]\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "acc:  0.6551724137931034 pre:  0.6551724137931034 rec:  1.0 spe:  0.0 f_score:  0.7916666666666666 c:  [95, 50, 0, 0]\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "acc:  0.6551724137931034 pre:  0.6551724137931034 rec:  1.0 spe:  0.0 f_score:  0.7916666666666666 c:  [95, 50, 0, 0]\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "acc:  0.6551724137931034 pre:  0.6551724137931034 rec:  1.0 spe:  0.0 f_score:  0.7916666666666666 c:  [95, 50, 0, 0]\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "acc:  0.6551724137931034 pre:  0.6551724137931034 rec:  1.0 spe:  0.0 f_score:  0.7916666666666666 c:  [95, 50, 0, 0]\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "acc:  0.6551724137931034 pre:  0.6551724137931034 rec:  1.0 spe:  0.0 f_score:  0.7916666666666666 c:  [95, 50, 0, 0]\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "acc:  0.6551724137931034 pre:  0.6551724137931034 rec:  1.0 spe:  0.0 f_score:  0.7916666666666666 c:  [95, 50, 0, 0]\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "acc:  0.6551724137931034 pre:  0.6551724137931034 rec:  1.0 spe:  0.0 f_score:  0.7916666666666666 c:  [95, 50, 0, 0]\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "acc:  0.6551724137931034 pre:  0.6551724137931034 rec:  1.0 spe:  0.0 f_score:  0.7916666666666666 c:  [95, 50, 0, 0]\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "acc:  0.6551724137931034 pre:  0.6551724137931034 rec:  1.0 spe:  0.0 f_score:  0.7916666666666666 c:  [95, 50, 0, 0]\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "acc:  0.6551724137931034 pre:  0.6551724137931034 rec:  1.0 spe:  0.0 f_score:  0.7916666666666666 c:  [95, 50, 0, 0]\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "acc:  0.6551724137931034 pre:  0.6551724137931034 rec:  1.0 spe:  0.0 f_score:  0.7916666666666666 c:  [95, 50, 0, 0]\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "acc:  0.6551724137931034 pre:  0.6551724137931034 rec:  1.0 spe:  0.0 f_score:  0.7916666666666666 c:  [95, 50, 0, 0]\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "acc:  0.6551724137931034 pre:  0.6551724137931034 rec:  1.0 spe:  0.0 f_score:  0.7916666666666666 c:  [95, 50, 0, 0]\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "acc:  0.6551724137931034 pre:  0.6551724137931034 rec:  1.0 spe:  0.0 f_score:  0.7916666666666666 c:  [95, 50, 0, 0]\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "acc:  0.6620689655172414 pre:  0.6597222222222222 rec:  1.0 spe:  0.02 f_score:  0.7949790794979079 c:  [95, 49, 1, 0]\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "acc:  0.6620689655172414 pre:  0.6597222222222222 rec:  1.0 spe:  0.02 f_score:  0.7949790794979079 c:  [95, 49, 1, 0]\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "acc:  0.6620689655172414 pre:  0.6597222222222222 rec:  1.0 spe:  0.02 f_score:  0.7949790794979079 c:  [95, 49, 1, 0]\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "acc:  0.6896551724137931 pre:  0.6785714285714286 rec:  1.0 spe:  0.1 f_score:  0.8085106382978724 c:  [95, 45, 5, 0]\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "acc:  0.6896551724137931 pre:  0.6785714285714286 rec:  1.0 spe:  0.1 f_score:  0.8085106382978724 c:  [95, 45, 5, 0]\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "acc:  0.7103448275862069 pre:  0.6934306569343066 rec:  1.0 spe:  0.16 f_score:  0.8189655172413793 c:  [95, 42, 8, 0]\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "acc:  0.7172413793103448 pre:  0.7045454545454546 rec:  0.9789473684210527 spe:  0.22 f_score:  0.8193832599118944 c:  [93, 39, 11, 2]\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "acc:  0.7448275862068966 pre:  0.7265625 rec:  0.9789473684210527 spe:  0.3 f_score:  0.8340807174887892 c:  [93, 35, 15, 2]\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "acc:  0.7517241379310344 pre:  0.7322834645669292 rec:  0.9789473684210527 spe:  0.32 f_score:  0.8378378378378378 c:  [93, 34, 16, 2]\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "acc:  0.7379310344827587 pre:  0.728 rec:  0.9578947368421052 spe:  0.32 f_score:  0.8272727272727272 c:  [91, 34, 16, 4]\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "acc:  0.7448275862068966 pre:  0.7416666666666667 rec:  0.9368421052631579 spe:  0.38 f_score:  0.827906976744186 c:  [89, 31, 19, 6]\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "acc:  0.7793103448275862 pre:  0.7787610619469026 rec:  0.9263157894736842 spe:  0.5 f_score:  0.8461538461538461 c:  [88, 25, 25, 7]\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "acc:  0.7793103448275862 pre:  0.7837837837837838 rec:  0.9157894736842105 spe:  0.52 f_score:  0.8446601941747574 c:  [87, 24, 26, 8]\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "acc:  0.7793103448275862 pre:  0.7837837837837838 rec:  0.9157894736842105 spe:  0.52 f_score:  0.8446601941747574 c:  [87, 24, 26, 8]\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "acc:  0.7793103448275862 pre:  0.794392523364486 rec:  0.8947368421052632 spe:  0.56 f_score:  0.8415841584158417 c:  [85, 22, 28, 10]\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "acc:  0.7931034482758621 pre:  0.8095238095238095 rec:  0.8947368421052632 spe:  0.6 f_score:  0.8500000000000001 c:  [85, 20, 30, 10]\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "acc:  0.7931034482758621 pre:  0.8155339805825242 rec:  0.8842105263157894 spe:  0.62 f_score:  0.8484848484848484 c:  [84, 19, 31, 11]\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "acc:  0.8 pre:  0.8235294117647058 rec:  0.8842105263157894 spe:  0.64 f_score:  0.8527918781725888 c:  [84, 18, 32, 11]\n",
            "Epoch 41\n",
            "-------------------------------\n",
            "acc:  0.7793103448275862 pre:  0.8315789473684211 rec:  0.8315789473684211 spe:  0.68 f_score:  0.8315789473684211 c:  [79, 16, 34, 16]\n",
            "Epoch 42\n",
            "-------------------------------\n",
            "acc:  0.7793103448275862 pre:  0.8315789473684211 rec:  0.8315789473684211 spe:  0.68 f_score:  0.8315789473684211 c:  [79, 16, 34, 16]\n",
            "Epoch 43\n",
            "-------------------------------\n",
            "acc:  0.7793103448275862 pre:  0.8315789473684211 rec:  0.8315789473684211 spe:  0.68 f_score:  0.8315789473684211 c:  [79, 16, 34, 16]\n",
            "Epoch 44\n",
            "-------------------------------\n",
            "acc:  0.7724137931034483 pre:  0.8297872340425532 rec:  0.8210526315789474 spe:  0.68 f_score:  0.8253968253968254 c:  [78, 16, 34, 17]\n",
            "Epoch 45\n",
            "-------------------------------\n",
            "acc:  0.7655172413793103 pre:  0.8351648351648352 rec:  0.8 spe:  0.7 f_score:  0.8172043010752689 c:  [76, 15, 35, 19]\n",
            "Epoch 46\n",
            "-------------------------------\n",
            "acc:  0.7586206896551724 pre:  0.8333333333333334 rec:  0.7894736842105263 spe:  0.7 f_score:  0.8108108108108109 c:  [75, 15, 35, 20]\n",
            "Epoch 47\n",
            "-------------------------------\n",
            "acc:  0.7586206896551724 pre:  0.8409090909090909 rec:  0.7789473684210526 spe:  0.72 f_score:  0.808743169398907 c:  [74, 14, 36, 21]\n",
            "Epoch 48\n",
            "-------------------------------\n",
            "acc:  0.7586206896551724 pre:  0.8409090909090909 rec:  0.7789473684210526 spe:  0.72 f_score:  0.808743169398907 c:  [74, 14, 36, 21]\n",
            "Epoch 49\n",
            "-------------------------------\n",
            "acc:  0.7517241379310344 pre:  0.8390804597701149 rec:  0.7684210526315789 spe:  0.72 f_score:  0.8021978021978021 c:  [73, 14, 36, 22]\n",
            "Epoch 50\n",
            "-------------------------------\n",
            "acc:  0.7517241379310344 pre:  0.8390804597701149 rec:  0.7684210526315789 spe:  0.72 f_score:  0.8021978021978021 c:  [73, 14, 36, 22]\n",
            "Done!\n"
          ]
        }
      ]
    }
  ]
}